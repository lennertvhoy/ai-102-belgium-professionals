---
sidebar_position: 2
---
# Lab 2: Hands-On with Intelligent Vision Systems

**Objective:** In this lab, you will gain practical experience with the core computer vision services in Azure. You will complete three independent tasks that reflect real-world challenges in the Belgian industrial and commercial landscape.

**Prerequisites:**
- Access to an Azure subscription.
- An Azure AI Vision resource, an Azure AI Custom Vision resource, and an Azure Video Indexer resource created in your subscription.

---

### Task 1: Automated Document Processing with the Read API (OCR)

**Scenario:** A logistics firm at Zeebrugge needs to automate the process of reading container numbers from scanned shipping documents to speed up their workflow. The documents are often low-quality scans and contain a mix of text.

**Instructions:**
1.  Navigate to your Azure AI Vision resource in the Azure portal.
2.  Open the **Vision Studio**.
3.  Under the **Optical Character Recognition** tab, select the **Extract text from files** feature. This uses the powerful Read API.
4.  Use one of the sample documents provided in the studio. Observe how the API accurately extracts all text, even from complex layouts.
5.  **Challenge:** Find an image of a Belgian license plate online. Upload it to the Vision Studio and see if the Read API can correctly extract the characters.
6.  Review the JSON output provided by the tool. Note how it provides the text content along with bounding box coordinates for each word.

> [Asset Suggestion: A screenshot of the Vision Studio interface showing a shipping document on one side and the extracted JSON output on the other, highlighting the container number.]

**Success Criterion:** You have successfully used the Read API via the Vision Studio to extract text from a document image and understand the structure of the JSON response.

---

### Task 2: Training a Custom Model for a Belgian Retailer

**Scenario:** A well-known Brussels bakery wants to build an AI-powered kiosk that can identify different types of pastries. You will use Azure AI Custom Vision to build a prototype.

**Instructions:**

**Part A: Image Classification (Is it a waffle?)**
1.  Go to the **Custom Vision** portal (customvision.ai).
2.  Create a new project with the **Classification** type and **Food** domain.
3.  Create two tags: `Waffle` and `Croissant`.
4.  Use the built-in image search to find and upload ~15 images for each tag.
5.  Train the model using the "Quick Training" option.
6.  Once trained, go to the **Performance** tab and review the precision and recall metrics.

**Part B: Object Detection (Find the pastries)**
1.  Create a second project, this time selecting the **Object Detection** type.
2.  Create one tag: `Pastry`.
3.  Upload 5-10 images that contain *multiple* pastries.
4.  Manually draw bounding boxes around each pastry in every image and assign the `Pastry` tag.
5.  Train the model and review its performance (note the Mean Average Precision (mAP) metric).

> [Asset Suggestion: A side-by-side comparison. Left: The Custom Vision classification interface with tagged images of waffles. Right: The object detection interface showing an image with bounding boxes drawn around multiple pastries.]

**Success Criterion:** You have trained both a classification and an object detection model, and can articulate the difference in the training process and use case for each.

---

### Task 3: Extracting Insights from Video with Azure Video Indexer

**Scenario:** A Belgian marketing agency has a large archive of video advertisements. They want to make this archive searchable to quickly find clips containing specific objects, people, or spoken words for a retrospective campaign.

**Instructions:**
1.  Navigate to the **Video Indexer** portal.
2.  Upload a short video from your computer (or use the sample library provided).
3.  Let the indexing process complete. This may take several minutes.
4.  Explore the detailed insights generated by the service:
    -   **Timeline:** View the automatically generated transcript, and see how it's synchronized with the video.
    -   **People:** See the faces of the people detected in the video.
    -   **Insights:** Look at the list of detected objects, labels (topics), and named entities.
5.  Use the search bar at the top to search for a word that was spoken in the video or an object that appeared. Notice how Video Indexer instantly finds the exact moments in the video where the query appears.

**Success Criterion:** You have successfully indexed a video and used the Video Indexer portal to navigate and search for insights within the video content.
